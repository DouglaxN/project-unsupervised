{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54866e91",
   "metadata": {},
   "source": [
    "## 1. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6c65a",
   "metadata": {},
   "source": [
    "O *dataset* original consistia em uma série temporal com **2.356.110 instâncias** e seis colunas principais (`date`, `state`, `name`, `code`, `cases`, `deaths`). Para atender aos objetivos de **aprendizado não supervisionado**, foi necessário transformar esses dados brutos em uma representação **descritiva e consolidada por município**.\n",
    "\n",
    "#### Limpeza e Agregação dos Dados\n",
    "\n",
    "Como cada município aparecia repetidamente ao longo do tempo, realizamos etapas de agregação para sintetizar seu perfil epidemiológico:\n",
    "\n",
    "- **Tratamento dos dados:** remoção de valores nulos, registros em branco e colunas irrelevantes para a análise de *clusters*.\n",
    "- **Engenharia de atributos (*feature engineering*):**\n",
    "  - `total_cases`: total acumulado de casos por município.\n",
    "  - `peak_cases`: maior número de casos registrados em um único dia, representando a intensidade do pico pandêmico local.\n",
    "\n",
    "Essas transformações permitiram capturar tanto a magnitude quanto a dinâmica da disseminação da doença em cada localidade.\n",
    "\n",
    "### Preparação para os Algoritmos de *Machine Learning*\n",
    "\n",
    "Considerando que os algoritmos de *Machine Learning* operam exclusivamente sobre dados numéricos e são sensíveis à escala das variáveis, aplicamos as seguintes técnicas:\n",
    "\n",
    "- **One-Hot Encoding:** conversão de variáveis categóricas em representações numéricas, possibilitando o seu uso nos modelos.\n",
    "- **Normalização (`StandardScaler`):** padronização das variáveis numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f3f69a",
   "metadata": {},
   "source": [
    "#### &emsp; 1.1 Baixando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intalação do gdown para pegar .csv bruto\n",
    "%pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fda03105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar o .csv bruto\n",
    "import os.path as path\n",
    "if not path.exists('./data/brazil_covid19_cities.csv'):\n",
    "  print(\"Baixando arquivo...\")\n",
    "  !gdown \"1sg9QK4g8QKCNgvfi6iNowcP75KNNkxUY\" -O ./data/brazil_covid19_cities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b291fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação do csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import umap\n",
    "df = pd.read_csv('./data/brazil_covid19_cities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929fb631",
   "metadata": {},
   "source": [
    "#### &emsp; 1.2 Modelando os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "721908e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear coluna name para city\n",
    "df = df.rename(columns={'name': 'city'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6c28fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma a coluna `date` em um objeto DateTime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['city', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83b4587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que casos e mortes são numéricos\n",
    "df['cases'] = pd.to_numeric(df['cases'], errors='coerce')\n",
    "df['deaths'] = pd.to_numeric(df['deaths'], errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['city', 'cases', 'deaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição de variáveis por cidade e estado\n",
    "features_city = df.groupby(['city', 'state']).agg({\n",
    "  'cases': ['max', 'mean', 'std'],\n",
    "  'deaths': ['max', 'mean', 'std'],\n",
    "  'date': 'count'\n",
    "})\n",
    "\n",
    "features_city.columns = [\n",
    "  'total_cases',\n",
    "  'mean_cases',\n",
    "  'std_cases',\n",
    "  'total_deaths',\n",
    "  'mean_deaths',\n",
    "  'std_deaths',\n",
    "  'days_recorded'\n",
    "]\n",
    "\n",
    "features_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f86378bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição de coluna `death_rate` (taxa de mortalidade)\n",
    "features_city['death_rate'] = (\n",
    "    features_city['total_deaths'] / features_city['total_cases']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b443636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crescimento dos casos\n",
    "df['new_cases'] = df.groupby(['city', 'state'])['cases'].diff().fillna(0)\n",
    "\n",
    "growth = df.groupby(['city', 'state'])['new_cases'].mean().rename('mean_daily_growth')\n",
    "features_city = features_city.join(growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "047e5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dia do primeiro caso\n",
    "first_case = df[df['cases'] > 0].groupby(['city','state'])['date'].min()\n",
    "first_case = (first_case - df['date'].min()).dt.days\n",
    "first_case = first_case.rename('days_until_first_case')\n",
    "\n",
    "features_city = features_city.join(first_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e40fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de registros com dados faltosos\n",
    "features_city = features_city.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e9891b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset de índices\n",
    "features_city = features_city.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9da71004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção do do campo `city`\n",
    "features_city.drop('city', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d08b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando one-hot encode no campo `state`\n",
    "features_city = pd.get_dummies(features_city, columns=['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4739f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalização do DataFrame tratado\n",
    "df = features_city.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093a85a",
   "metadata": {},
   "source": [
    "## Estruturação dos Dados pós-processamento\n",
    "\n",
    "Após as etapas de limpeza, o conjunto de dados consolidado passou a contar com 5.570 instâncias. Isso representa a totalidade dos municípios brasileiros e 37 colunas estruturadas.\n",
    "\n",
    "| Categoria                          | Métrica / Atributo           | Descrição                                                                 |\n",
    "|-----------------------------------|------------------------------|---------------------------------------------------------------------------|\n",
    "| **Magnitude e Dispersão**          | `total_cases`                | Total acumulado de casos por município.                                   |\n",
    "|                                   | `mean_cases`                 | Média diária de casos registrados ao longo do período analisado.          |\n",
    "|                                   | `std_cases`                  | Desvio padrão dos casos diários, indicando a variabilidade do contágio.   |\n",
    "|                                   | `total_deaths`               | Total acumulado de óbitos por município.                                  |\n",
    "|                                   | `mean_deaths`                | Média diária de óbitos registrados no período.                             |\n",
    "| **Indicadores Epidemiológicos**    | `death_rate`                 | Taxa de letalidade por município (óbitos / casos confirmados).            |\n",
    "| **Avançados**                     | `mean_daily_growth`          | Velocidade média de crescimento diário dos casos.                          |\n",
    "|                                   | `days_until_first_case`      | Número de dias até o registro do primeiro caso no município.               |\n",
    "| **Localização Geográfica**         | `state_AC` – `state_TO`      | Variáveis binárias geradas por One-Hot Encoding para representar os estados |\n",
    "|                                   |                              | brasileiros, permitindo capturar regionalidade sem ordem numérica.        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bed9bf",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "658dc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db86f84",
   "metadata": {},
   "source": [
    "## 2. Redução de Dimensionalidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6710610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduc = dict()    # Objeto pra agupar os resultados dos métodos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99dfba3",
   "metadata": {},
   "source": [
    "#### &emsp; 2.1 Aplicação de PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4b67395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando a PCA\n",
    "pca_full = PCA()\n",
    "pca_full.fit(df_scaled)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "df_scaled_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Adiciona o resultado ao conjunto de resultados\n",
    "df_reduc['pca'] = df_scaled_pca\n",
    "\n",
    "# Calculando a variancia explicada acumulada\n",
    "variancia_acumulada = np.cumsum(pca_full.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a moldura com 1 linha e 2 colunas\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Visualização PCA\n",
    "ax1.scatter(df_scaled_pca[:, 0], df_scaled_pca[:, 1], alpha=0.6, edgecolors='w', s=40)\n",
    "ax1.set_title('Visualização PCA (n_components=2)', fontsize=14)\n",
    "ax1.set_xlabel('Primeiro Componente Principal (PC1)')\n",
    "ax1.set_ylabel('Segundo Componente Principal (PC2)')\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Vizualização da Variância\n",
    "ax2.plot(range(1, len(variancia_acumulada) + 1), variancia_acumulada, marker='o', linestyle='--')\n",
    "ax2.axhline(y=0.80, color='r', linestyle='-', label='Corte de 80%') # Linha de corte\n",
    "ax2.set_title('Variância Explicada Acumulada', fontsize=14)\n",
    "ax2.set_xlabel('Número de Componentes')\n",
    "ax2.set_ylabel('Variância Coberta (0 a 1.0)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Ajustando o layout para não sobrepor\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print informativo\n",
    "print(f\"Variância Total com 2 componentes: {variancia_acumulada[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee8c0b2",
   "metadata": {},
   "source": [
    "#### &emsp;  2.2 Aplicação de t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "687ab633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo as preplexidades para teste\n",
    "perplexidades = [20, 30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea94c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando muldura para as imagnes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 7))\n",
    "\n",
    "# Adiciona o resultado ao conjunto de resultados\n",
    "df_reduc['tsne'] = dict()\n",
    "\n",
    "for i, perp in enumerate(perplexidades):\n",
    "    # Aplicando o t-SNE (usamos random_state para resultados reproduzíveis)\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, max_iter=1000, learning_rate=200, random_state=42)\n",
    "    df_tsne = tsne.fit_transform(df_scaled)\n",
    "\n",
    "    df_reduc['tsne'][perp] = df_tsne\n",
    "\n",
    "    # Plotando no subplot correspondente (axes[i])\n",
    "    axes[i].scatter(df_tsne[:, 0], df_tsne[:, 1], alpha=0.6, s=20)\n",
    "    axes[i].set_title(f't-SNE (Perplexity={perp})', fontsize=14)\n",
    "    axes[i].set_xlabel('Componente t-SNE 1')\n",
    "    axes[i].set_ylabel('Componente t-SNE 2')\n",
    "    axes[i].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Ajusta o espaçamento para os títulos não cortarem\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed4ba3",
   "metadata": {},
   "source": [
    "#### &emsp;  2.3 Aplicação de UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9042ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vizinhos = [15, 30, 100]\n",
    "df_reduc['umap'] = dict()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(22, 7))\n",
    "\n",
    "for i, n in enumerate(vizinhos):\n",
    "    # Aplicando o UMAP\n",
    "    reducer = umap.UMAP(n_neighbors=n, min_dist=0.1, random_state=42)\n",
    "    df_umap = reducer.fit_transform(df_scaled)\n",
    "\n",
    "    # Adiciona o resultado ao conjunto de resultados\n",
    "    df_reduc['umap'][n] = df_umap\n",
    "\n",
    "    # Plotando no subplot correspondente\n",
    "    scatter = axes[i].scatter(df_umap[:, 0], df_umap[:, 1], alpha=0.6, s=15, cmap='viridis')\n",
    "    axes[i].set_title(f'UMAP (n_neighbors={n})', fontsize=14)\n",
    "    axes[i].set_xlabel('UMAP 1')\n",
    "    axes[i].set_ylabel('UMAP 2')\n",
    "    axes[i].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Efeito do Parâmetro n_neighbors no UMAP', fontsize=16, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb2dae",
   "metadata": {},
   "source": [
    "## 3. Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420339d7",
   "metadata": {},
   "source": [
    "### &emsp;  3.1 Aplicação de K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e31b9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans_t = df_reduc['tsne'][30]   # <-- Placeholder, liga o df usado a um dos outputs (PCA/t-SNE/UMAP)\n",
    "df_kmeans_u = df_reduc['umap'][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba085c",
   "metadata": {},
   "source": [
    "#### 3.1.1 Método do cotovelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ac196",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 11)\n",
    "inertias = []\n",
    "clustering_results = []\n",
    "\n",
    "for k in k_range:\n",
    "  model = KMeans(n_clusters=k, max_iter=150, random_state=42)\n",
    "  model.fit(df_kmeans)\n",
    "\n",
    "  current_inertia = 0\n",
    "  for i in range(k):\n",
    "    cluster_points = df_kmeans[model.labels_ == i]\n",
    "    current_inertia += np.sum((cluster_points - model.cluster_centers_[i])**2)\n",
    "\n",
    "  inertias.append(current_inertia)\n",
    "  clustering_results.append({'labels': model.labels_, 'centroids': model.cluster_centers_})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertias, 'bo-')\n",
    "plt.xlabel('Número de Clusters (K)')\n",
    "plt.ylabel('Inércia (WGSS)')\n",
    "plt.title('Método do Cotovelo para Encontrar o K Ótimo')\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "\n",
    "# Marcar o ponto escolhido (k=4) no gráfico\n",
    "k_target = 4\n",
    "if k_target in k_range:\n",
    "    y_target = inertias[k_target - 1]\n",
    "    plt.scatter(k_target, y_target, marker='*', color='red', s=200, zorder=5, label='k=4: valor ótimo')\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0cd5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação do k-means com k=4 e redução com t-SNE\n",
    "kmeans = KMeans(n_clusters=4, max_iter=500, random_state=42)\n",
    "kmeans.fit(df_kmeans_t)\n",
    "kmeans_labels_t = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b245b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicação do k-means com k=4 e redução com UMAP\n",
    "kmeans = KMeans(n_clusters=4, max_iter=500, random_state=42)\n",
    "kmeans.fit(df_kmeans_u)\n",
    "kmeans_labels_u = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(16,7))\n",
    "\n",
    "# Plot 1: Agrupamento do k-means\n",
    "axes[0].scatter(df_kmeans_t[:, 0], df_kmeans_t[:, 1], c=kmeans_labels_t, s=50, cmap='viridis', edgecolor='k')\n",
    "axes[0].set_title(\"Clusters encontrados pelo k-means (t-SNE)\")\n",
    "axes[0].set_xlabel('Componente 1')\n",
    "axes[0].set_ylabel('Componente 2')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot 2: Classes reais do dataset\n",
    "scatter = axes[1].scatter(df_kmeans_u[:, 0], df_kmeans_u[:, 1], c=kmeans_labels_u, s=50, cmap='viridis', edgecolor='k')\n",
    "axes[1].set_title(\"Clusters encontrados peo k-means (UMAP)\")\n",
    "axes[1].set_xlabel('Componente 1')\n",
    "axes[1].set_ylabel('Componente 2')\n",
    "axes[1].grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9df53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualização do k-means\n",
    "# plt.figure(figsize=(10,6))\n",
    "\n",
    "# # Plotar cada cluster separadamente para criar legenda clara\n",
    "# unique_labels = np.unique(kmeans_labels)\n",
    "# cmap = plt.get_cmap('viridis', len(unique_labels))\n",
    "# for i, label in enumerate(unique_labels):\n",
    "#   mask = kmeans_labels == label\n",
    "#   plt.scatter(df_kmeans[mask, 0], df_kmeans[mask, 1], s=50, color=cmap(i), edgecolor='k', label=f'Cluster {int(label)}')\n",
    "\n",
    "# # Criação do gráfico\n",
    "# plt.title('Resultado da clusterização com K-means (k=4)')\n",
    "# plt.xlabel('Componente 1')\n",
    "# plt.ylabel('Componente 2')\n",
    "# plt.grid(True)\n",
    "# plt.legend(loc='upper right', title='Clusters')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cedfb",
   "metadata": {},
   "source": [
    "### &emsp;  3.2 Aplicação de DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c9eea",
   "metadata": {},
   "source": [
    "## 4. Discussão de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65802a04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
