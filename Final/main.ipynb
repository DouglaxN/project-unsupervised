{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54866e91",
   "metadata": {},
   "source": [
    "## 1. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6c65a",
   "metadata": {},
   "source": [
    "O *dataset* original consistia em uma série temporal com **2.356.110 instâncias** e seis colunas principais (`date`, `state`, `name`, `code`, `cases`, `deaths`). Para atender aos objetivos de **aprendizado não supervisionado**, foi necessário transformar esses dados brutos em uma representação **descritiva e consolidada por município**.\n",
    "\n",
    "#### Limpeza e Agregação dos Dados\n",
    "\n",
    "Como cada município aparecia repetidamente ao longo do tempo, realizamos etapas de agregação para sintetizar seu perfil epidemiológico:\n",
    "\n",
    "- **Tratamento dos dados:** remoção de valores nulos, registros em branco e colunas irrelevantes para a análise de *clusters*.\n",
    "- **Engenharia de atributos (*feature engineering*):**\n",
    "  - `total_cases`: total acumulado de casos por município.\n",
    "  - `peak_cases`: maior número de casos registrados em um único dia, representando a intensidade do pico pandêmico local.\n",
    "\n",
    "Essas transformações permitiram capturar tanto a magnitude quanto a dinâmica da disseminação da doença em cada localidade.\n",
    "\n",
    "### Preparação para os Algoritmos de *Machine Learning*\n",
    "\n",
    "Considerando que os algoritmos de *Machine Learning* operam exclusivamente sobre dados numéricos e são sensíveis à escala das variáveis, aplicamos as seguintes técnicas:\n",
    "\n",
    "- **One-Hot Encoding:** conversão de variáveis categóricas em representações numéricas, possibilitando o seu uso nos modelos.\n",
    "- **Normalização (`StandardScaler`):** padronização das variáveis numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &emsp; 1.1 Baixando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (5.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from gdown) (4.14.3)\n",
      "Requirement already satisfied: filelock in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from gdown) (3.20.3)\n",
      "Requirement already satisfied: requests[socks] in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from gdown) (4.67.2)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from beautifulsoup4->gdown) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (2026.1.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Intalação do gdown para pegar .csv bruto\n",
    "%pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fda03105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/dev/clones/project-unsupervised/.venv/lib/python3.13/site-packages/gdown/__main__.py:139: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1sg9QK4g8QKCNgvfi6iNowcP75KNNkxUY\n",
      "From (redirected): https://drive.google.com/uc?id=1sg9QK4g8QKCNgvfi6iNowcP75KNNkxUY&confirm=t&uuid=dd11573c-0916-4784-b580-18ecf5d8a5c7\n",
      "To: /mnt/dev/clones/project-unsupervised/Final/data/brazil_covid19_cities.csv\n",
      "100%|████████████████████████████████████████| 106M/106M [00:59<00:00, 1.77MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Baixar o .csv bruto\n",
    "!gdown --id \"1sg9QK4g8QKCNgvfi6iNowcP75KNNkxUY\" -O ./data/brazil_covid19_cities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b291fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação do csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import umap\n",
    "df = pd.read_csv('./data/brazil_covid19_cities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929fb631",
   "metadata": {},
   "source": [
    "#### &emsp; 1.2 Modelando os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721908e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear coluna name para city\n",
    "df = df.rename(columns={'name': 'city'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c28fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma a coluna `date` em um objeto DateTime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['city', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que casos e mortes são numéricos\n",
    "df['cases'] = pd.to_numeric(df['cases'], errors='coerce')\n",
    "df['deaths'] = pd.to_numeric(df['deaths'], errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['city', 'cases', 'deaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição de variáveis por cidade e estado\n",
    "features_city = df.groupby(['city', 'state']).agg({\n",
    "  'cases': ['max', 'mean', 'std'],\n",
    "  'deaths': ['max', 'mean', 'std'],\n",
    "  'date': 'count'\n",
    "})\n",
    "\n",
    "features_city.columns = [\n",
    "  'total_cases',\n",
    "  'mean_cases',\n",
    "  'std_cases',\n",
    "  'total_deaths',\n",
    "  'mean_deaths',\n",
    "  'std_deaths',\n",
    "  'days_recorded'\n",
    "]\n",
    "\n",
    "features_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86378bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição de coluna `death_rate` (taxa de mortalidade)\n",
    "features_city['death_rate'] = (\n",
    "    features_city['total_deaths'] / features_city['total_cases']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crescimento dos casos\n",
    "df['new_cases'] = df.groupby(['city', 'state'])['cases'].diff().fillna(0)\n",
    "\n",
    "growth = df.groupby(['city', 'state'])['new_cases'].mean().rename('mean_daily_growth')\n",
    "features_city = features_city.join(growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dia do primeiro caso\n",
    "first_case = df[df['cases'] > 0].groupby(['city','state'])['date'].min()\n",
    "first_case = (first_case - df['date'].min()).dt.days\n",
    "first_case = first_case.rename('days_until_first_case')\n",
    "\n",
    "features_city = features_city.join(first_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção de registros com dados faltosos\n",
    "features_city = features_city.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9891b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset de índices\n",
    "features_city = features_city.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da71004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção do do campo `city`\n",
    "features_city.drop('city', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08b519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando one-hot encode no campo `state`\n",
    "features_city = pd.get_dummies(features_city, columns=['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4739f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalização do DataFrame tratado\n",
    "df = features_city.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae3213",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9db86f84",
   "metadata": {},
   "source": [
    "## 2. Redução de Dimensionalidade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99dfba3",
   "metadata": {},
   "source": [
    "#### &emsp; 2.1 Aplicação de PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee8c0b2",
   "metadata": {},
   "source": [
    "#### &emsp;  2.2 Aplicação de t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ba051",
   "metadata": {},
   "source": [
    "#### &emsp;  2.3 Aplicação de UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb2dae",
   "metadata": {},
   "source": [
    "## 3. Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420339d7",
   "metadata": {},
   "source": [
    "#### &emsp;  3.1 Aplicação de K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9cedfb",
   "metadata": {},
   "source": [
    "#### &emsp;  3.2 Aplicação de DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c9eea",
   "metadata": {},
   "source": [
    "## 4. Discussão de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65802a04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
